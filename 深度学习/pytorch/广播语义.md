

[Broadcasting semantics &mdash; PyTorch 2.0 documentation](https://pytorch.org/docs/stable/notes/broadcasting.html)



一种自动 copy 成相等尺寸的运算



在[pytorch](https://so.csdn.net/so/search?q=pytorch&spm=1001.2101.3001.7020)的张量计算中，“广播”指的是当满足一定条件时，较小的张量能够自动扩张成合适尺寸的大张量，使得能够进行计算。

# 条件

当一对张量满足下面的条件时，它们才是可以被“广播”的。

1、每个张量至少有一个维度。

2、迭代维度尺寸时，从**尾部**（也就是从后往前）开始，依次每个维度的尺寸必须满足以下之一：

- **相等**。
- 其中一个张量的维度**尺寸为1**。
- 其中一个张量**不存在**这个维度。

---

# 例子

光看条件可能会有点迷，下面是官方文档中的几个例子。

```python
import torch
```

首先，显然相同形状的张量是可以广播的（或者说不需要广播）。、

```python
x = torch.empty(5, 7, 3)y = torch.empty(5, 7, 3)
```

`(x+y).size()`输出`torch.Size([5, 7, 3])`。  
一般而言，我们可以从后往前分析一对张量是不是“broadcastable”。

```python
x = torch.empty(5, 3, 4, 1)y = torch.empty(   3, 1, 1)
```

我们依次分析：  
对倒数第一个维度，两者尺寸相同，符合“相等”的条件。  
对倒数第二个维度，y的尺寸为1，符合“其中一个张量尺寸为1”的条件。  
对倒数第三个维度，两者尺寸相同，符合“相等”的条件。  
对倒数第四个维度，y的该维度不存在，符合“其中一个张量不存在这个维度”的条件。  
综上，这两个张量可以广播。  
其实，x可以比y多出更多的维度，都满足该维度有“其中一个张量不存在这个维度”的条件。  
举个反例：

```python
x = torch.empty(5, 2, 4, 1)y = torch.empty(   3, 1, 1)
```

这里若x+y就无法广播了，因为从后往前遇到倒数第三个维度时会被卡住，不满足任何一个条件。  
此外，对`torch.empty((0,))`，它也无法和其他任何张量广播，可以输出发现其结果为`tensor([])`，是空的，这就不满足“每个张量至少有一个维度”这个条件。
